{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model_dict = {}\n",
    "val_dict = {}\n",
    "quest_val_dict = {}\n",
    "quest_model_dict = {}\n",
    "\n",
    "question_data = pd.read_csv('question_info.txt', sep=\"\\t\",header=None)\n",
    "question_data.columns = [\"Q_id\",\"Q_tag\",\"Word_seq\",\"Char_seq\",\"Likes\",\"Ans\",\"Top_Ans\"]\n",
    "del question_data[\"Word_seq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation  import train_test_split\n",
    "from sklearn.grid_search  import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def get_Best_Param(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0,stratify = y)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "  \n",
    "    clf = GridSearchCV(SVC(C=1), tuned_parameters)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(clf.best_params_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(tokenizer=lambda x: x.split(\"/\"))\n",
    "q_tag_vector = cv.fit_transform(question_data[\"Q_tag\"].astype(str))\n",
    "char_seq_vector = cv.fit_transform(question_data[\"Char_seq\"].astype(str))\n",
    "del question_data[\"Q_tag\"]\n",
    "del question_data[\"Char_seq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "char_col_list=[\"char_\"+str(num) for num in range(char_seq_vector.shape[1])]\n",
    "tag_col_list=[\"tag_\"+str(num) for num in range(q_tag_vector.shape[1])]\n",
    "question_data =  pd.concat([question_data,pd.DataFrame(q_tag_vector.toarray(), columns=tag_col_list)],axis=1)\n",
    "#question_data =  pd.concat([question_data,pd.DataFrame(char_seq_vector.toarray(), columns=char_col_list)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expert_data = pd.read_csv('user_info.txt', sep=\"\\t\",header=None)\n",
    "expert_data.columns = [\"U_id\",\"U_tag\",\"Word_seq\",\"Char_seq\"]\n",
    "del expert_data[\"Word_seq\"]\n",
    "U_tag_vector = cv.fit_transform(expert_data[\"U_tag\"].astype(str))\n",
    "char_seq_vector = cv.fit_transform(expert_data[\"Char_seq\"].astype(str))\n",
    "del expert_data[\"U_tag\"]\n",
    "del expert_data[\"Char_seq\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_col_list=[\"char_\"+str(num) for num in range(char_seq_vector.shape[1])]\n",
    "tag_col_list=[\"U_tag_\"+str(num) for num in range(U_tag_vector.shape[1])]\n",
    "expert_data =  pd.concat([expert_data,pd.DataFrame(U_tag_vector.toarray(), columns=tag_col_list)],axis=1)\n",
    "expert_data =  pd.concat([expert_data,pd.DataFrame(char_seq_vector.toarray(), columns=char_col_list)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expert_question_dist = pd.read_csv('invited_info_train.txt', sep=\"\\t\",header=None)\n",
    "expert_question_dist.columns = [\"Q_id\",\"U_id\",\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for expert,per_user_dist in expert_question_dist.groupby([\"U_id\"]):\n",
    "    final_data_user = pd.merge(question_data, per_user_dist, on='Q_id',how = 'inner')\n",
    "#final_data = pd.merge(final_data, expert_data, on='U_id', how='inner')\n",
    "    del final_data_user[\"Q_id\"]\n",
    "    del final_data_user[\"U_id\"]\n",
    "    final_target_user = final_data_user[\"output\"]\n",
    "    if len(final_data_user.output.unique()) == 1: \n",
    "        val_dict[expert] = final_data_user.output.unique() \n",
    "        del final_data_user[\"output\"]\n",
    "    else:\n",
    "        del final_data_user[\"output\"]\n",
    "        '''if final_data.shape[0] > 4 and final_target.sum() > 1:\n",
    "            print(\"finding best param\")\n",
    "            print(final_target)\n",
    "            get_Best_Param(final_data,final_target)'''\n",
    "        model = SVC(probability=True)\n",
    "        model.fit(final_data_user, final_target_user)\n",
    "        model_dict[expert] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for question,per_user_dist in expert_question_dist.groupby([\"Q_id\"]):\n",
    "    final_data_quest = pd.merge(expert_data, per_user_dist, on='U_id',how = 'inner')\n",
    "#final_data = pd.merge(final_data, expert_data, on='U_id', how='inner')\n",
    "    del final_data_quest[\"Q_id\"]\n",
    "    del final_data_quest[\"U_id\"]\n",
    "    final_target_quest = final_data_quest[\"output\"]\n",
    "    if len(final_data_quest.output.unique()) == 1: \n",
    "        quest_val_dict[question] = final_data_quest.output.unique() \n",
    "        del final_data_quest[\"output\"]\n",
    "    else:\n",
    "        del final_data_quest[\"output\"]\n",
    "        '''if final_data.shape[0] > 4 and final_target.sum() > 1:\n",
    "            print(\"finding best param\")\n",
    "            print(final_target)\n",
    "            get_Best_Param(final_data,final_target)'''\n",
    "        model = SVC(probability=True)\n",
    "        model.fit(final_data_quest, final_target_quest)\n",
    "        quest_model_dict[question] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_data = pd.read_csv('validate_nolabel.txt', sep=\",\")[[0,1]]\n",
    "validation_data.columns = [\"Q_id\",\"U_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 13] Permission denied: 'val.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-07fd5f34bbfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutputdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"output\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mfinal_predicted_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mper_user_dist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutputdf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mfinal_predicted_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'val.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mper_user_dist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ranjini\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal, **kwds)\u001b[0m\n\u001b[1;32m   1342\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1344\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ranjini\\Anaconda2\\lib\\site-packages\\pandas\\formats\\format.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1524\u001b[0m             f = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m   1525\u001b[0m                             \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1526\u001b[0;31m                             compression=self.compression)\n\u001b[0m\u001b[1;32m   1527\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ranjini\\Anaconda2\\lib\\site-packages\\pandas\\io\\common.pyc\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path, mode, encoding, compression)\u001b[0m\n\u001b[1;32m    424\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 13] Permission denied: 'val.csv'"
     ]
    }
   ],
   "source": [
    "for expert,per_user_dist in validation_data.groupby([\"U_id\"]):\n",
    "    per_user_dist.reset_index(drop=True, inplace=True)\n",
    "    predicted_data = pd.merge(per_user_dist,question_data, on='Q_id', how='inner')\n",
    "    if expert in val_dict.keys():\n",
    "        output =  np.empty([1,per_user_dist.shape[0]])\n",
    "        output.fill(val_dict[expert][0])  \n",
    "        outputdf = pd.DataFrame(output.T)\n",
    "        final_predicted_data = pd.concat([per_user_dist,outputdf],axis=1)\n",
    "        final_predicted_data.to_csv('val.csv',mode='a',sep=',', index=False, header = False)\n",
    "    elif expert in model_dict.keys():\n",
    "        del predicted_data[\"Q_id\"]\n",
    "        del predicted_data[\"U_id\"] \n",
    "        predicted = model_dict[expert].predict_proba(predicted_data)\n",
    "        outputdf = pd.DataFrame(predicted)[1]\n",
    "        outputdf.columns = [\"output\"]\n",
    "        final_predicted_data = pd.concat([per_user_dist,outputdf],axis=1)\n",
    "        final_predicted_data.to_csv('val.csv',mode='a',sep=',', index=False, header = False)\n",
    "    else:\n",
    "        output =  np.empty([1,per_user_dist.shape[0]])\n",
    "        output.fill(0)  \n",
    "        outputdf = pd.DataFrame(output.T)\n",
    "        final_predicted_data = pd.concat([per_user_dist,outputdf],axis=1)\n",
    "        '''for question,per_quest_dist in per_user_dist.groupby([\"Q_id\"]):\n",
    "            per_quest_dist.reset_index(drop=True, inplace=True)\n",
    "            predicted_data = pd.merge(per_quest_dist,expert_data, on='U_id', how='inner')\n",
    "            if question in quest_val_dict.keys():\n",
    "                output =  np.empty([1,per_quest_dist.shape[0]])\n",
    "                output.fill(quest_val_dict[question][0])  \n",
    "                outputdf = pd.DataFrame(output.T)\n",
    "                final_predicted_data = pd.concat([per_quest_dist,outputdf],axis=1)\n",
    "                final_predicted_data.to_csv('val1.csv',mode='a',sep=',', index=False, header = False)\n",
    "            elif question in quest_model_dict.keys():\n",
    "                del predicted_data[\"Q_id\"]\n",
    "                del predicted_data[\"U_id\"] \n",
    "                predicted = quest_model_dict[question].predict_proba(predicted_data)\n",
    "                outputdf = pd.DataFrame(predicted)[1]\n",
    "                outputdf.columns = [\"output\"]\n",
    "                final_predicted_data = pd.concat([per_quest_dist,outputdf],axis=1)\n",
    "    # expert not in distribution (ie) he has not ranked anything\n",
    "                final_predicted_data.to_csv('val1.csv',mode='a',sep=',', index=False, header = False)\n",
    "            else:\n",
    "                output =  np.empty([1,per_quest_dist.shape[0]])\n",
    "                output.fill(0)  \n",
    "                outputdf = pd.DataFrame(output.T)\n",
    "                final_predicted_data = pd.concat([per_quest_dist,outputdf],axis=1)'''\n",
    "        final_predicted_data.to_csv('val.csv',mode='a',sep=',', index=False, header = False)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
